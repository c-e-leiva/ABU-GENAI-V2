# ğŸ’¬ Prompt y Modelos de IA

Esta secciÃ³n describe cÃ³mo se construyen las instrucciones que recibe el modelo de lenguaje (prompt engineering), los modelos utilizados en ABU v2 y cÃ³mo se ajustan sus parÃ¡metros para lograr una interacciÃ³n empÃ¡tica y funcional.

---

## ğŸ§  Prompt Manager

El mÃ³dulo `core/prompt_manager.py` se encarga de construir un **prompt dinÃ¡mico** que guÃ­a al modelo (GPT-4 o GPT-3.5) para generar respuestas personalizadas y contextuales.

### Componentes del prompt:

- **Perfil del usuario** (nombre, edad, provincia, dificultades, preferencias)
- **Estado emocional** actual (determinante para el tono de respuesta)
- **Historial conversacional resumido** (mediante LangChain)
- **IntenciÃ³n del mensaje del usuario**
- **Instrucciones especÃ­ficas del sistema y la personalidad del asistente**

El objetivo es generar respuestas cÃ¡lidas, claras y adaptadas al contexto y necesidad emocional de cada usuario.

---

## ğŸ§ª Modelos de lenguaje utilizados

| Tarea                       | Modelo           | JustificaciÃ³n                                     |
|----------------------------|------------------|--------------------------------------------------|
| ConversaciÃ³n principal     | GPT-4 Turbo      | Alta calidad, respuestas empÃ¡ticas y coherentes |
| Tareas auxiliares          | GPT-3.5 Turbo    | ResÃºmenes, tareas especÃ­ficas con menor costo    |

Los modelos se seleccionan dinÃ¡micamente segÃºn el tipo de tarea.

---

## ğŸ›ï¸ ParÃ¡metros ajustables

ABU adapta los parÃ¡metros del modelo segÃºn el tipo de interacciÃ³n para equilibrar **precisiÃ³n, creatividad y calidez**.

| Contexto                     | Temperatura | Finalidad                     |
|-----------------------------|-------------|-------------------------------|
| Emergencias / respuestas crÃ­ticas | 0.2         | PrecisiÃ³n y control            |
| ConversaciÃ³n general         | 0.7         | Naturalidad y empatÃ­a         |
| ResÃºmenes y anÃ¡lisis         | 0.6         | Claridad con algo de flexibilidad |

---

## ğŸ§¬ Memoria conversacional

- Implementada en `core/memoria.py` usando **LangChain**.
- Permite mantener el contexto de la conversaciÃ³n entre turnos.
- Mejora la coherencia y la personalizaciÃ³n de las respuestas.
- TambiÃ©n se usa para detectar situaciones sensibles (mÃ³dulo `detectar_emergencia.py`).

---

## ğŸ“Œ Detalles tÃ©cnicos adicionales

- Se usan roles "system", "user" y "assistant" para estructurar los mensajes enviados a la API.
- El historial del usuario es preprocesado y resumido para evitar sobrepasar el lÃ­mite de tokens.
- Las respuestas se filtran para ajustar tono y forma antes de ser enviadas por voz (TTS) o texto.

---

> ğŸ§© MÃ³dulos involucrados:  
> `core/prompt_manager.py`  
> `core/openai_service.py`  
> `core/memoria.py`  
> `features/resumen_historial.py`
